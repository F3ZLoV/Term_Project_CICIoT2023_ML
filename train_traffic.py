# 0. ê³µí†µ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import pandas as pd
import numpy as np
import os
import warnings
from tqdm import tqdm

# (ì¶”ê°€) ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
import matplotlib.pyplot as plt
import seaborn as sns

# (ì¶”ê°€) ê³„ì¸µì  ìƒ˜í”Œë§ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split

# # 3, 4ë‹¨ê³„ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, \
    confusion_matrix

# (ì„ íƒ) í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™” ì‹œ)
try:
    plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows
except:
    pass  # Windowsê°€ ì•„ë‹ ê²½ìš° ë¬´ì‹œ
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

print("--- 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ ---")

# --- 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì„¤ì • ---

# ğŸš¨ CICIOT2023 CSV íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í„°ë¦¬ ê²½ë¡œ
DATASET_DIRECTORY = 'CICIoT2023/'

# â­ï¸ (ì¤‘ìš”) ë©”ëª¨ë¦¬ ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ìƒ˜í”Œë§ ë¹„ìœ¨
# 0.1 = ê° íŒŒì¼ì—ì„œ 10%ì˜ ë°ì´í„°ë§Œ ê³„ì¸µì  ìƒ˜í”Œë§ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
# ë©”ëª¨ë¦¬ê°€ ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ 0.05 (5%) ë“±ìœ¼ë¡œ ë” ë‚®ì¶°ë³´ì„¸ìš”.
SAMPLING_RATIO = 0.1

try:
    all_files = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]
    all_files.sort()
    print(f"\n--- 1. ë°ì´í„° ë¡œë“œ ---")
    print(f"ì´ {len(all_files)}ê°œ CSV íŒŒì¼ ë°œê²¬.")
    print(f"ì„¤ì •ëœ ìƒ˜í”Œë§ ë¹„ìœ¨: {SAMPLING_RATIO * 100}%")
except FileNotFoundError:
    print(f"ì˜¤ë¥˜: '{DATASET_DIRECTORY}' ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# --- 2. ë°ì´í„° ì „ì²˜ë¦¬ (í”¼ì²˜/ë ˆì´ë¸” ì •ì˜ ë° ë§¤í•‘) ---

# # 4. X (íŠ¹ì„±)ì™€ y (íƒ€ê²Ÿ) ë¶„ë¦¬ (ì»¬ëŸ¼ ì´ë¦„ ì •ì˜)
X_columns = [
    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',
    'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',
    'rst_flag_number', 'psh_flag_number', 'ack_flag_number',
    'ece_flag_number', 'cwr_flag_number', 'ack_count',
    'syn_count', 'fin_count', 'urg_count', 'rst_count',
    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',
    'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',
    'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',
    'Radius', 'Covariance', 'Variance', 'Weight',
]
y_column = 'label'

print(f"\n--- 2. ë°ì´í„° ì „ì²˜ë¦¬ ---")
print(f"X (íŠ¹ì„±) ì»¬ëŸ¼ {len(X_columns)}ê°œ ì •ì˜ ì™„ë£Œ.")
print(f"y (íƒ€ê²Ÿ) ì»¬ëŸ¼ '{y_column}' ì •ì˜ ì™„ë£Œ.")

# ë ˆì´ë¸” ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ì •ì˜
dict_8_classes = {
    'DDoS-RSTFINFlood': 'DDoS', 'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS',
    'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS', 'DDoS-ICMP_Flood': 'DDoS',
    'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS',
    'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS',
    'DDoS-SlowLoris': 'DDoS', 'DDoS-HTTP_Flood': 'DDoS', 'DoS-UDP_Flood': 'DoS',
    'DoS-SYN_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',
    'Mirai-greeth_flood': 'Mirai', 'Mirai-greip_flood': 'Mirai', 'Mirai-udpplain': 'Mirai',
    'Recon-PingSweep': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',
    'VulnerabilityScan': 'Recon', 'Recon-HostDiscovery': 'Recon',
    'DNS_Spoofing': 'Spoofing', 'MITM-ArpSpoofing': 'Spoofing',
    'BenignTraffic': 'Benign', 'BrowserHijacking': 'Web', 'Backdoor_Malware': 'Web',
    'XSS': 'Web', 'Uploading_Attack': 'Web', 'SqlInjection': 'Web',
    'CommandInjection': 'Web', 'DictionaryBruteForce': 'BruteForce'
}
dict_2_classes = {'BenignTraffic': 'Benign'}

print("2-Class / 8-Class ë ˆì´ë¸” ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ì •ì˜ ì™„ë£Œ.")


# (ê°œì„ ) â­ï¸ ìƒ˜í”Œë§ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ë°ì´í„° ë¡œë“œ/ì „ì²˜ë¦¬ í•¨ìˆ˜
def load_and_preprocess(files, description, sample_ratio):
    """íŒŒì¼ ëª©ë¡ì„ ì½ì–´ ìƒ˜í”Œë§í•˜ê³ , í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹œ í›„ ì „ì²˜ë¦¬/ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤."""
    sampled_dfs = []
    print(f"\n{description} ë°ì´í„° ë¡œë“œ ë° ìƒ˜í”Œë§(ë¹„ìœ¨ {sample_ratio * 100}%) ì¤‘...")

    for f in tqdm(files):
        file_path = os.path.join(DATASET_DIRECTORY, f)
        try:
            df = pd.read_csv(file_path, low_memory=False)

            # 1. NaN/Infinity ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´ (ìŠ¤ì¼€ì¼ë§ ì „)
            df.replace([np.inf, -np.inf], np.nan, inplace=True)
            df.fillna(0, inplace=True)

            # 2. ê³„ì¸µì  ìƒ˜í”Œë§ (Stratified Sampling)
            try:
                _, df_sample = train_test_split(
                    df,
                    test_size=sample_ratio,  # test_sizeë¥¼ ìƒ˜í”Œë§ ë¹„ìœ¨ë¡œ ì‚¬ìš©
                    stratify=df[y_column],  # ë ˆì´ë¸” ë¹„ìœ¨ ìœ ì§€
                    random_state=42
                )
            except ValueError:
                df_sample = df.sample(frac=sample_ratio, random_state=42)

            sampled_dfs.append(df_sample)

        except Exception as e:
            print(f"íŒŒì¼ {f} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # ìƒ˜í”Œë§ëœ ëª¨ë“  DataFrameì„ í•˜ë‚˜ë¡œ í•©ì¹¨
    full_df = pd.concat(sampled_dfs, ignore_index=True)

    # 3. X(íŠ¹ì„±)ì™€ y(íƒ€ê²Ÿ) ë¶„ë¦¬
    X = full_df[X_columns]
    y_raw = full_df[y_column]

    # 4. ìŠ¤ì¼€ì¼ë§ ì ìš© (scalerëŠ” 3ë‹¨ê³„ì—ì„œ ë¯¸ë¦¬ fit ë˜ì–´ ìˆì–´ì•¼ í•¨)
    X_scaled = scaler.transform(X)
    X_scaled_df = pd.DataFrame(X_scaled, columns=X_columns)

    return X_scaled_df, y_raw


print("\n--- 2. ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ ---")

# --- 3. ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ---

# # 1. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  (íŒŒì¼ ê¸°ì¤€ 80:20)
split_index = int(len(all_files) * 0.8)
training_files = all_files[:split_index]
test_files = all_files[split_index:]

print(f"\n--- 3. ëª¨ë¸ í›ˆë ¨ ---")
print(f"[ë°ì´í„° ë¶„í•  í˜„í™©]")
print(f"í›ˆë ¨ìš© íŒŒì¼ {len(training_files)}ê°œ, í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ {len(test_files)}ê°œ.")

# # 3. ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (í•™ìŠµ)
print("\n[ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ (StandardScaler)]")
print("í›ˆë ¨ íŒŒì¼ë“¤ë¡œ StandardScaler í•™ìŠµ(fitting) ì¤‘ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...")
scaler = StandardScaler()
for train_set_file in tqdm(training_files):
    file_path = os.path.join(DATASET_DIRECTORY, train_set_file)
    try:
        df_chunk = pd.read_csv(file_path, usecols=X_columns, low_memory=False)
        df_chunk.replace([np.inf, -np.inf], np.nan, inplace=True)
        df_chunk.fillna(0, inplace=True)
        scaler.partial_fit(df_chunk)  # ì ì§„ì  í•™ìŠµ
    except Exception as e:
        print(f"íŒŒì¼ {train_set_file} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
del df_chunk
print("StandardScaler í•™ìŠµ ì™„ë£Œ.")

# (ê°œì„ ) ìƒ˜í”Œë§ëœ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
try:
    X_train, y_train_raw = load_and_preprocess(training_files, "í›ˆë ¨", sample_ratio=SAMPLING_RATIO)
    X_test, y_test_raw = load_and_preprocess(test_files, "í…ŒìŠ¤íŠ¸", sample_ratio=SAMPLING_RATIO)

    print(f"\n[ë°ì´í„° ìƒ˜í”Œë§ í›„ Shape]")
    print(f"X_train shape: {X_train.shape}, y_train shape: {y_train_raw.shape}")
    print(f"X_test shape: {X_test.shape}, y_test shape: {y_test_raw.shape}")

except MemoryError:
    print(f"\n[ì˜¤ë¥˜] ìƒ˜í”Œë§(í˜„ì¬ {SAMPLING_RATIO * 100}%) í›„ì—ë„ ë©”ëª¨ë¦¬ ë¶€ì¡±.")
    print("ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ì˜ SAMPLING_RATIO ê°’ì„ ë” ë‚®ì¶°ì„œ (ì˜ˆ: 0.05) ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    exit()

# ì‹œë‚˜ë¦¬ì˜¤ë³„ y (íƒ€ê²Ÿ) ë°ì´í„° ìƒì„±
y_train_34 = y_train_raw
y_test_34 = y_test_raw
y_train_8 = y_train_raw.map(dict_8_classes).fillna('Benign')
y_test_8 = y_test_raw.map(dict_8_classes).fillna('Benign')
y_train_2 = y_train_raw.map(dict_2_classes).fillna('Attack')
y_test_2 = y_test_raw.map(dict_2_classes).fillna('Attack')

# --- 1-bis. ğŸ“Š ìƒì„¸í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA) (ìƒ˜í”Œë§ ë°ì´í„° í™œìš©) ---
print(f"\n--- 1-bis. ìƒì„¸ EDA (ìƒ˜í”Œë§ëœ í›ˆë ¨ ë°ì´í„° ê¸°ì¤€) ---")

# (ì¶”ê°€) 1-1. (ì‹œê°í™”) 2-Class (Attack/Benign) ë¶„í¬ íŒŒì´ ì°¨íŠ¸
try:
    plt.figure(figsize=(8, 8))
    label_counts = y_train_2.value_counts()
    plt.pie(label_counts, labels=label_counts.index, autopct='%1.2f%%',
            startangle=90, colors=['#ff9999', '#66b3ff'])
    plt.title(f'ìƒ˜í”Œë§ëœ í›ˆë ¨ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬ (2-Class, {SAMPLING_RATIO * 100}% Sample)')
    plt.legend()
    plt.savefig("eda_1_pie_2_classes.png")
    print("[ì‹œê°í™”] 'eda_1_pie_2_classes.png' ì €ì¥ ì™„ë£Œ")
except Exception as e:
    print(f"ì‹œê°í™” 1 (íŒŒì´ ì°¨íŠ¸) ì˜¤ë¥˜: {e}")

# (ìˆ˜ì •) 1-2. (ì‹œê°í™”) 34-Class ì„¸ë¶€ ë ˆì´ë¸” ë¶„í¬ (ìƒìœ„ 20ê°œ)
try:
    plt.figure(figsize=(12, 10))
    # ì›ë³¸ 34ê°œ í´ë˜ìŠ¤ ì¤‘ ìƒìœ„ 20ê°œë§Œ
    top_20_labels = y_train_34.value_counts().nlargest(20)
    sns.barplot(y=top_20_labels.index, x=top_20_labels.values)
    plt.title(f'ìƒ˜í”Œë§ëœ í›ˆë ¨ ë°ì´í„° ì„¸ë¶€ ë ˆì´ë¸” ë¶„í¬ (Top 20 / 34-Class)')
    plt.xlabel('ë°ì´í„° ìˆ˜')
    plt.ylabel('ê³µê²© ìœ í˜• (ì›ë³¸)')
    plt.xscale('log')  # ìˆ˜ëŸ‰ ì°¨ì´ê°€ í¬ë¯€ë¡œ log ìŠ¤ì¼€ì¼
    plt.tight_layout()
    plt.savefig("eda_2_bar_top20_labels.png")
    print("[ì‹œê°í™”] 'eda_2_bar_top20_labels.png' ì €ì¥ ì™„ë£Œ (ë¡œê·¸ ìŠ¤ì¼€ì¼)")
except Exception as e:
    print(f"ì‹œê°í™” 2 (ì„¸ë¶€ ë ˆì´ë¸”) ì˜¤ë¥˜: {e}")

# (ì¶”ê°€) 1-3. (ì‹œê°í™”) ì£¼ìš” íŠ¹ì„± ë¶„í¬ (Benign vs Attack) - Box Plot
try:
    features_to_plot = ['flow_duration', 'Rate', 'Tot sum', 'AVG']
    print(f"[ì‹œê°í™”] ì£¼ìš” íŠ¹ì„± {features_to_plot} ë°•ìŠ¤í”Œë¡¯ ì €ì¥ ì¤‘...")

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    axes = axes.flatten()

    temp_df = X_train[features_to_plot].copy()
    # (ì£¼ì˜) ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°(X_train)ëŠ” ì´ë¯¸ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë³€í™˜ë¨
    # ì›ë³¸ ë¶„í¬ë¥¼ ë³´ë ¤ë©´ load_and_preprocessì—ì„œ X(ìŠ¤ì¼€ì¼ë§ ì „)ë¥¼ ë°˜í™˜í•´ì•¼ í•¨
    # ì—¬ê¸°ì„œëŠ” ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ë¹„êµ
    temp_df['label'] = y_train_2.values

    for i, feature in enumerate(features_to_plot):
        sns.boxplot(data=temp_df, x='label', y=feature, ax=axes[i], showfliers=False)  # Outlier ì œì™¸
        axes[i].set_title(f"'{feature}' ë¶„í¬ (Benign vs Attack) - Scaled Data")
        # (ì°¸ê³ ) Yì¶• ìŠ¤ì¼€ì¼ì´ ë§¤ìš° ì‘ì„ ìˆ˜ ìˆìŒ (ì´ë¯¸ ìŠ¤ì¼€ì¼ë§ë¨)
        # axes[i].set_yscale('log') # Box plotì€ log scale ì ìš©ì´ ê¹Œë‹¤ë¡œìš¸ ìˆ˜ ìˆìŒ

    plt.tight_layout()
    plt.savefig("eda_3_feature_boxplot.png")
    print("[ì‹œê°í™”] 'eda_3_feature_boxplot.png' ì €ì¥ ì™„ë£Œ")
    del temp_df
except Exception as e:
    print(f"ì‹œê°í™” 3 (íŠ¹ì„± ë°•ìŠ¤í”Œë¡¯) ì˜¤ë¥˜: {e}")

# 1-4. (ì‹œê°í™”) ì£¼ìš” íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ (ìœ ì§€)
try:
    print("[ì‹œê°í™”] ì£¼ìš” íŠ¹ì„± ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ì €ì¥ ì¤‘...")
    corr_features = X_columns[:15]
    corr_matrix = X_train[corr_features].corr()

    plt.figure(figsize=(12, 10))
    sns.heatmap(corr_matrix, annot=True, fmt='.1f', cmap='coolwarm_r')
    plt.title('ì£¼ìš” íŠ¹ì„± ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ (ìƒìœ„ 15ê°œ) - Scaled Data')
    plt.tight_layout()
    plt.savefig("eda_4_correlation_heatmap.png")
    print("[ì‹œê°í™”] 'eda_4_correlation_heatmap.png' ì €ì¥ ì™„ë£Œ")
    del corr_matrix
except Exception as e:
    print(f"ì‹œê°í™” 4 (ìƒê´€ê´€ê³„) ì˜¤ë¥˜: {e}")

# # 4. ëª¨ë¸ ìƒì„± ë° í›ˆë ¨ (EDA ì™„ë£Œ í›„ ì§„í–‰)
print("\n[ëª¨ë¸ ìƒì„± ë° í›ˆë ¨]")
# (max_iter=1000: ìˆ˜ë ´ ê²½ê³  ë°©ì§€)

#%% ëª¨ë¸ 1 (2-Class)
print("LogisticRegression (2 classes) í›ˆë ¨ ì‹œì‘...")
model_2 = LogisticRegression(n_jobs=-1, max_iter=1000)
model_2.fit(X_train, y_train_2)

#%% ëª¨ë¸ 2 (8-Class)
print("LogisticRegression (8 classes) í›ˆë ¨ ì‹œì‘...")
model_8 = LogisticRegression(n_jobs=-1, max_iter=1000)
model_8.fit(X_train, y_train_8)

#%% ëª¨ë¸ 3 (34-Class)
print("LogisticRegression (34 classes) í›ˆë ¨ ì‹œì‘...")
model_34 = LogisticRegression(n_jobs=-1, max_iter=1000)
model_34.fit(X_train, y_train_34)

print("\n--- 3. ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ---")

# --- 4. ëª¨ë¸ í‰ê°€ ë° í•´ì„ ---
print(f"\n--- 4. ëª¨ë¸ í‰ê°€ ë° í•´ì„ ---")

# # 2. ì˜ˆì¸¡ ìˆ˜í–‰
print("\n[í…ŒìŠ¤íŠ¸ ë°ì´í„°(X_test)ì— ëŒ€í•œ ì˜ˆì¸¡ ì™„ë£Œ]")
y_pred_2 = model_2.predict(X_test)
y_pred_8 = model_8.predict(X_test)
y_pred_34 = model_34.predict(X_test)


# (ì¶”ê°€) Confusion Matrix ì‹œê°í™” í•¨ìˆ˜
def plot_confusion_matrix(y_true, y_pred, labels, model_name, filename):
    """Confusion Matrixë¥¼ ì‹œê°í™”í•˜ê³  ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        cm = confusion_matrix(y_true, y_pred, labels=labels)
        show_annot = len(labels) <= 10

        plt.figure(figsize=(max(10, len(labels) * 0.8), max(8, len(labels) * 0.6)))
        sns.heatmap(cm, annot=show_annot, fmt='d', cmap='Blues',
                    xticklabels=labels, yticklabels=labels)
        plt.title(f'Confusion Matrix - {model_name}')
        plt.ylabel('Actual Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.savefig(filename)
        print(f"[ì‹œê°í™”] '{filename}' ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"ì‹œê°í™” (í˜¼ë™ í–‰ë ¬: {model_name}) ì˜¤ë¥˜: {e}")


# # 3. ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥ ë° í•´ì„
def print_evaluation_metrics(model_name, y_true, y_pred, average_mode='macro', pos_label=None):
    """PPTì˜ í‰ê°€ ì§€í‘œì²˜ëŸ¼ ì„±ëŠ¥ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    accuracy = accuracy_score(y_true, y_pred)
    print(f"\n##### {model_name} #####")
    print(f"[ì •í™•ë„(Accuracy)]: {accuracy:.4f} (ì•½ {accuracy * 100:.2f}%)")

    print(f"\n[ë¶„ë¥˜ ë¦¬í¬íŠ¸(Classification Report)]: (average='{average_mode}')")
    # zero_division=0: ìƒ˜í”Œì´ ì—†ëŠ” í´ë˜ìŠ¤ì— ëŒ€í•´ 0ìœ¼ë¡œ ì²˜ë¦¬
    report = classification_report(y_true, y_pred, zero_division=0)
    print(report)

    # binary ëª¨ë“œì¼ ë•Œ pos_labelì„ ì „ë‹¬
    if average_mode == 'binary' and pos_label is not None:
        print(
            f"* Precision (ì •ë°€ë„ - {average_mode}): {precision_score(y_true, y_pred, average=average_mode, pos_label=pos_label, zero_division=0):.4f}")
        print(f"* Recall (ì¬í˜„ìœ¨ - {average_mode}): {recall_score(y_true, y_pred, average=average_mode, pos_label=pos_label, zero_division=0):.4f}")
        print(f"* F1-score (ì¡°í™” í‰ê·  - {average_mode}): {f1_score(y_true, y_pred, average=average_mode, pos_label=pos_label, zero_division=0):.4f}")
    else:
        print(
            f"* Precision (ì •ë°€ë„ - {average_mode}): {precision_score(y_true, y_pred, average=average_mode, zero_division=0):.4f}")
        print(f"* Recall (ì¬í˜„ìœ¨ - {average_mode}): {recall_score(y_true, y_pred, average=average_mode, zero_division=0):.4f}")
        print(f"* F1-score (ì¡°í™” í‰ê·  - {average_mode}): {f1_score(y_true, y_pred, average=average_mode, zero_division=0):.4f}")


# 2ì§„ ë¶„ë¥˜ í‰ê°€ (Attack/Benign)
print_evaluation_metrics("LogisticRegression (2 classes)", y_test_2, y_pred_2, average_mode='binary')
plot_confusion_matrix(y_test_2, y_pred_2, model_2.classes_,
                      "2 classes", "result_images/eval_cm_2_classes.png")

# 8ì¢… ë¶„ë¥˜ í‰ê°€
print_evaluation_metrics("LogisticRegression (8 classes)", y_test_8, y_pred_8, average_mode='macro')
plot_confusion_matrix(y_test_8, y_pred_8, model_8.classes_,
                      "8 classes", "result_images/eval_cm_8_classes.png")

# 34ì¢… ë¶„ë¥˜ í‰ê°€ (Confusion MatrixëŠ” ë„ˆë¬´ ì»¤ì„œ ë¹„í™œì„±í™”)
print_evaluation_metrics("LogisticRegression (34 classes)", y_test_34, y_pred_34, average_mode='macro')

# --- 4-1. ë³´ë„ˆìŠ¤ â€“ íŠ¹ì„±ì´ ê³µê²©/ì •ìƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ ---
print(f"\n--- 4-1. ë³´ë„ˆìŠ¤: íŠ¹ì„± ì˜í–¥ë ¥ (2-Class ëª¨ë¸) ---")
try:
    target_class_index = list(model_2.classes_).index('Attack')
    print(f"('{model_2.classes_[target_class_index]}' í´ë˜ìŠ¤ ê¸°ì¤€ ê³„ìˆ˜)")

    coefficients = model_2.coef_[target_class_index]
    coef_df = pd.DataFrame({'Feature': X_columns, 'Coefficient': coefficients})
    coef_df['abs_coef'] = np.abs(coef_df['Coefficient'])
    coef_df = coef_df.sort_values(by='abs_coef', ascending=False)

    print("\n[íŠ¹ì„±(Feature)ì´ 'Attack' íƒì§€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ (ê³„ìˆ˜)]")
    print(coef_df[['Feature', 'Coefficient']].head(10))

    # ë³´ë„ˆìŠ¤ ì‹œê°í™” (ìƒìœ„/í•˜ìœ„ 10ê°œ)
    top_n = 10
    bottom_n = 10
    top_features = coef_df.head(top_n)
    bottom_features = coef_df.tail(bottom_n).sort_values(by='Coefficient', ascending=True)

    plt.figure(figsize=(10, 6))
    sns.barplot(x='Coefficient', y='Feature', data=top_features)
    plt.title(f"'Attack' í™•ë¥ ì„ ë†’ì´ëŠ” ìƒìœ„ {top_n}ê°œ íŠ¹ì„± (Scaled Data)")
    plt.savefig("eval_feature_importance_positive.png", bbox_inches='tight')
    print(f"\n[ì‹œê°í™”] 'eval_feature_importance_positive.png' ì €ì¥ ì™„ë£Œ")

    plt.figure(figsize=(10, 6))
    sns.barplot(x='Coefficient', y='Feature', data=bottom_features)
    plt.title(f"'Attack' í™•ë¥ ì„ ë‚®ì¶”ëŠ” (Benignì— ê°€ê¹Œìš´) ìƒìœ„ {bottom_n}ê°œ íŠ¹ì„± (Scaled Data)")
    plt.savefig("eval_feature_importance_negative.png", bbox_inches='tight')
    print(f"[ì‹œê°í™”] 'eval_feature_importance_negative.png' ì €ì¥ ì™„ë£Œ")

except Exception as e:
    print(f"ì‹œê°í™” (íŠ¹ì„± ì˜í–¥ë ¥) ì˜¤ë¥˜: {e}")

print("\n--- ëª¨ë“  ì‘ì—… ì™„ë£Œ ---")