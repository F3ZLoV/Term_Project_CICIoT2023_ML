{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-02T10:27:55.417807Z",
     "start_time": "2025-12-02T10:27:54.309903Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T10:34:03.958538Z",
     "start_time": "2025-12-02T10:27:55.440544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. 설정 및 데이터 로드 ---\n",
    "DATASET_DIRECTORY = 'CICIoT2023/'\n",
    "# 튜닝 속도를 위해 샘플링 비율을 낮게 설정 (5%만 사용)\n",
    "# 실제 학습때는 이 비율을 높이거나 찾은 파라미터를 적용하세요.\n",
    "TUNING_SAMPLE_RATIO = 0.05\n",
    "\n",
    "# 컬럼 정의 (기존 코드 참조)\n",
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "    'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "    'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "    'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "    'syn_count', 'fin_count', 'urg_count', 'rst_count',\n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "    'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "    'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "    'Radius', 'Covariance', 'Variance', 'Weight',\n",
    "]\n",
    "y_column = 'label'\n",
    "\n",
    "# 8-Class 매핑 (대표적인 시나리오로 튜닝 진행)\n",
    "dict_8_classes = {\n",
    "    'DDoS-RSTFINFlood': 'DDoS', 'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS',\n",
    "    'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS', 'DDoS-ICMP_Flood': 'DDoS',\n",
    "    'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS',\n",
    "    'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS',\n",
    "    'DDoS-SlowLoris': 'DDoS', 'DDoS-HTTP_Flood': 'DDoS', 'DoS-UDP_Flood': 'DoS',\n",
    "    'DoS-SYN_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',\n",
    "    'Mirai-greeth_flood': 'Mirai', 'Mirai-greip_flood': 'Mirai', 'Mirai-udpplain': 'Mirai',\n",
    "    'Recon-PingSweep': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',\n",
    "    'VulnerabilityScan': 'Recon', 'Recon-HostDiscovery': 'Recon',\n",
    "    'DNS_Spoofing': 'Spoofing', 'MITM-ArpSpoofing': 'Spoofing',\n",
    "    'BenignTraffic': 'Benign', 'BrowserHijacking': 'Web', 'Backdoor_Malware': 'Web',\n",
    "    'XSS': 'Web', 'Uploading_Attack': 'Web', 'SqlInjection': 'Web',\n",
    "    'CommandInjection': 'Web', 'DictionaryBruteForce': 'BruteForce'\n",
    "}\n",
    "\n",
    "def load_subset_data(directory, sample_ratio):\n",
    "    \"\"\"튜닝을 위해 데이터의 일부만 로드\"\"\"\n",
    "    all_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    # 파일 개수도 줄여서 로딩 (속도 최적화)\n",
    "    subset_files = all_files[:10]\n",
    "\n",
    "    dfs = []\n",
    "    print(f\"데이터 로드 중 (파일 {len(subset_files)}개, 비율 {sample_ratio})...\")\n",
    "    for f in subset_files:\n",
    "        try:\n",
    "            path = os.path.join(directory, f)\n",
    "            df = pd.read_csv(path)\n",
    "            # 샘플링\n",
    "            df_sample = df.sample(frac=sample_ratio, random_state=42)\n",
    "            dfs.append(df_sample)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 전처리\n",
    "    full_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    full_df.fillna(0, inplace=True)\n",
    "\n",
    "    X = full_df[X_columns]\n",
    "    y = full_df[y_column].map(dict_8_classes).fillna('Benign')\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# 데이터 로드\n",
    "if os.path.exists(DATASET_DIRECTORY):\n",
    "    X, y = load_subset_data(DATASET_DIRECTORY, TUNING_SAMPLE_RATIO)\n",
    "\n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # 훈련/검증 세트 분리\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_enc, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"학습 데이터 크기: {X_train.shape}\")\n",
    "\n",
    "    # --- 2. LightGBM 하이퍼파라미터 튜닝 ---\n",
    "    print(\"\\n[LightGBM] 하이퍼파라미터 튜닝 시작...\")\n",
    "\n",
    "    # LightGBM 파라미터 범위 설정\n",
    "    # num_leaves: 트리의 복잡도 결정 (가장 중요). 2^max_depth보다 작게 설정.\n",
    "    # min_child_samples: 과적합 방지.\n",
    "    lgbm_params = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'num_leaves': [31, 64, 128],\n",
    "        'max_depth': [-1, 10, 20],\n",
    "        'min_child_samples': [20, 50, 100],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    lgbm = LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "    # RandomizedSearchCV 실행 (n_iter=10: 10번의 랜덤 조합 시도)\n",
    "    lgbm_search = RandomizedSearchCV(\n",
    "        lgbm, lgbm_params, n_iter=10, scoring='accuracy', cv=3, verbose=1, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    lgbm_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"LightGBM 최적 파라미터: {lgbm_search.best_params_}\")\n",
    "    print(f\"LightGBM 최고 정확도 (CV): {lgbm_search.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "    # --- 3. XGBoost 하이퍼파라미터 튜닝 ---\n",
    "    print(\"\\n[XGBoost] 하이퍼파라미터 튜닝 시작...\")\n",
    "\n",
    "    # XGBoost 파라미터 범위 설정\n",
    "    xgb_params = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "\n",
    "    xgb_search = RandomizedSearchCV(\n",
    "        xgb_model, xgb_params, n_iter=5, scoring='accuracy', cv=3, verbose=1, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    xgb_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"XGBoost 최적 파라미터: {xgb_search.best_params_}\")\n",
    "    print(f\"XGBoost 최고 정확도 (CV): {xgb_search.best_score_:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"데이터 디렉토리를 찾을 수 없어 튜닝을 수행하지 못했습니다.\")"
   ],
   "id": "ef81c6cef0bab599",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 중 (파일 10개, 비율 0.05)...\n",
      "학습 데이터 크기: (94678, 46)\n",
      "\n",
      "[LightGBM] 하이퍼파라미터 튜닝 시작...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "LightGBM 최적 파라미터: {'subsample': 0.8, 'num_leaves': 128, 'n_estimators': 500, 'min_child_samples': 20, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "LightGBM 최고 정확도 (CV): 0.9928\n",
      "\n",
      "[XGBoost] 하이퍼파라미터 튜닝 시작...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "XGBoost 최적 파라미터: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.2, 'colsample_bytree': 0.8}\n",
      "XGBoost 최고 정확도 (CV): 0.9932\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
